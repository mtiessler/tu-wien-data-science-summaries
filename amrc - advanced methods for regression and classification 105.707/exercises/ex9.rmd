---
title: "AMRC: Exercise 9 - 11912007"
output: pdf_document
documentclass: article
papersize: a4
pagestyle: empty
geometry:
    - top=5mm
    - bottom=5mm
    - left=5mm
    - right=5mm
header-includes:
    # title
    - \usepackage{titling}
    - \setlength{\droptitle}{-15pt}
    - \pretitle{\vspace{-30pt}\begin{center}\LARGE}
    - \posttitle{\end{center}\vspace{-50pt}}    
    # content
    - \usepackage{scrextend}
    - \changefontsizes[8pt]{8pt}
    # code
    - \usepackage{fancyvrb}
    - \fvset{fontsize=\fontsize{6pt}{6pt}\selectfont}
    - \usepackage{listings}
    - \lstset{basicstyle=\fontsize{6pt}{6pt}\selectfont\ttfamily}
    # code output
    - \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\fontsize{6pt}{6pt}}
---

<!-- https://tuwel.tuwien.ac.at/pluginfile.php/4264985/mod_resource/content/10/ex9.pdf -->

# Analysis

The assignment asks us to analyze the Diabetes dataset from the ROCit package to develop a classification model for diabetes based on the variable 'dtest'. After loading the data, we need to consider which variables to include in the model. It's reasonable to exclude predictor variables that may not be directly relevant to diabetes diagnosis or those with high multicollinearity. After excluding these variables, we removed observations with missing values using `na.omit()`.

For the analysis, we randomly selected about 75% of the observations from each class as a training set, built the classification model, and predicted group membership for the remaining test data. The code output shows that a logistic regression model was fitted first. The results indicate that the model faced some issues, likely due to the high number of predictors and possible multicollinearity, as evidenced by the large standard errors and p-values for most coefficients.

To address these issues, a sparse logistic regression model was fitted using `cv.glmnet` with the argument `family="binomial"`. This approach helps in variable selection and dealing with multicollinearity. The results show improved performance, with a reduced set of predictors and better model fit.

Next, Generalized Additive Models (GAMs) were employed using the `gam()` function from the mgcv package. The smooth functions were defined for numeric variables, while factor variables were included as is. The code output reveals that the GAM model was fitted with smooth terms for 'id' and 'whr', suggesting these variables have non-linear relationships with the response.

The summary of the GAM model shows that the smooth term for 'whr' (waist-to-hip ratio) is more complex and potentially more important in the model compared to 'id'. The effective degrees of freedom (edf) for 'whr' is 1.4257, indicating a non-linear relationship, while 'id' has an edf close to zero, suggesting it might not be necessary in the model.

The plots of the explanatory variables against their smoothed values provide visual insights into these relationships. The plot for 'whr' shows a non-linear pattern, confirming its importance and complexity in the model.

The confusion matrix and misclassification error for the test set are reported in the output. The GAM model achieved an accuracy of 0.82, corresponding to a misclassification rate of 0.18, which is a reasonable performance for this dataset.

Variable selection was performed using the `step.Gam` function, as suggested in the assignment. The results indicate that only 'gender' and 'glyhb' (glycosylated hemoglobin) were retained in the final model. This suggests that these two variables are the most important predictors of diabetes in this dataset.

Finally, a GAM was fitted using only the selected variables ('gender' and 'glyhb'). The summary output shows that both variables are highly significant in the model. Interestingly, this simplified model achieved perfect classification on the test set, with an accuracy of 1 and a misclassification rate of 0. However, this perfect performance should be interpreted cautiously, as it might indicate overfitting to the training data. The final model, using only gender and glycosylated hemoglobin as predictors, shows excellent predictive power, but further validation on new data would be necessary to confirm its generalizability.

# Code

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# klaR workaround
Sys.setenv(PATH=paste("/opt/homebrew/bin", Sys.getenv("PATH"), sep=":"))
pkgs <- c("classInt", "questionr", "klaR")
for (p in pkgs) {
    if (!requireNamespace(p, quietly = TRUE)) install.packages(p, type="source")
    library(p, character.only = TRUE)
}

pkgs <- c("ISLR", "gclus", "assertthat", "ggplot2", "ROCit", "glmnet", "mgcv", "gam")
for (p in pkgs) {
    if (!requireNamespace(p, quietly = TRUE)) install.packages(p, repos = "https://cran.rstudio.com")
    library(p, character.only = TRUE)
}

options(repr.plot.width=20, repr.plot.height=5)

options(scipen=999)
set.seed(42)
data(Diabetes)
```

```{r, echo=TRUE, message=FALSE, warning=FALSE, fig.width=20, fig.height=6}
set.seed(42)

data(Diabetes) # from ROCit package

Diabetes$dtest <- ifelse(Diabetes$dtest == "+", 1, 0) # encode dtest as binary
diabetes_clean <- na.omit(Diabetes) # drop missing vals

# 2/3 holdout split
sample_idx <- sample(c(TRUE, FALSE), nrow(diabetes_clean), replace=TRUE, prob=c(2/3, 1/3))
train_data <- diabetes_clean[sample_idx, ]
test_data <- diabetes_clean[!sample_idx, ]

#
# logistic regression
#

# lasso variable selection
cv_model <- cv.glmnet(model.matrix(~.-1, train_data), train_data$dtest, family="binomial", type.measure="class")
final_model <- glmnet(model.matrix(~.-1, train_data), train_data$dtest, family="binomial", lambda=cv_model$lambda.min)
selected_vars <- which(coef(final_model) != 0)

# train
formula <- as.formula(paste("dtest ~", paste(colnames(model.matrix(~.-1, train_data))[selected_vars], collapse="+")))
model <- glm(formula, data=train_data, family="binomial")
summary(model)

# eval
predicted_probs <- predict(model, test_data, type = "response")
threshold <- 0.5
predicted_classes <- ifelse(predicted_probs > threshold, 1, 0)
conf_matrix <- table(predicted_classes, test_data$dtest)
print(conf_matrix)
cat("accuracy: ", sum(diag(conf_matrix)) / sum(conf_matrix), "\n")
cat("misclassification rate: ", 1 - sum(diag(conf_matrix)) / sum(conf_matrix), "\n")

# 
# generalized additive model
# 

k_selection <- TRUE
if (!k_selection) {
    # basic GAM model without k selection
    numeric_vars <- sapply(train_data, is.numeric)
    formula_parts <- vector("character", length(selected_vars))
    for(i in seq_along(selected_vars)) {
        var_name <- colnames(model.matrix(~.-1, train_data))[selected_vars[i]]
        if(numeric_vars[var_name]) {
            formula_parts[i] <- paste0("s(", var_name, ", bs='tp')")  # using thin plate regression splines
        } else {
            formula_parts[i] <- var_name
        }
    }
    gam_formula <- as.formula(paste("dtest ~", paste(formula_parts, collapse="+")))
    gam_model <- mgcv::gam(gam_formula, data=train_data, family=binomial(), method="REML")
} else {
    # GAM model with k selection
    gam_model <- mgcv::gam(dtest ~ s(id, bs="tp") + s(whr, bs="tp"), data=train_data, family=binomial(), method="REML", select=TRUE)
}

gam.check(gam_model)
summary(gam_model)
concurvity(gam_model) # concurvity is GAM's version of multicollinearity
par(mfrow=c(2,2))
plot(gam_model, page=1, shade=TRUE, shade.col="lightblue")

# eval
gam_predicted_probs <- predict(gam_model, test_data, type = "response")
gam_predicted_classes <- ifelse(gam_predicted_probs > threshold, 1, 0)
gam_conf_matrix <- table(gam_predicted_classes, test_data$dtest)
print(gam_conf_matrix)
cat("accuracy: ", sum(diag(gam_conf_matrix)) / sum(gam_conf_matrix), "\n")
cat("misclassification rate: ", 1 - sum(diag(gam_conf_matrix)) / sum(gam_conf_matrix), "\n")

# 
# GAM variable selection (old school)
# 

cat("all variables:", colnames(diabetes_clean), "\n")

full_model <- gam(dtest ~ s(age) + s(bmi) + s(whr) + s(glyhb) + s(chol) + s(stab.glu) + s(hdl) + gender, family = binomial, data = train_data)
scope <- list(
    "age" = ~ 1 + age + s(age, df=4),
    "bmi" = ~ 1 + bmi + s(bmi, df=4),
    "whr" = ~ 1 + whr + s(whr, df=4),
    "glyhb" = ~ 1 + glyhb + s(glyhb, df=4),
    "chol" = ~ 1 + chol + s(chol, df=4),
    "stab.glu" = ~ 1 + stab.glu + s(stab.glu, df=4),
    "hdl" = ~ 1 + hdl + s(hdl, df=4)
)
step_model <- step.Gam(full_model, scope = scope, direction = "both")
summary(step_model)

# eval
step_predicted_probs <- predict(step_model, test_data, type = "response")
step_predicted_classes <- ifelse(step_predicted_probs > threshold, 1, 0)
step_conf_matrix <- table(step_predicted_classes, test_data$dtest)
print(step_conf_matrix)
cat("accuracy: ", sum(diag(step_conf_matrix)) / sum(step_conf_matrix), "\n")
cat("misclassification rate: ", 1 - sum(diag(step_conf_matrix)) / sum(step_conf_matrix), "\n")

# 
# GAM variable selection (modern)
# 

select_model <- mgcv::gam(dtest ~ s(age) + s(bmi) + s(whr) + s(glyhb) + s(chol) + s(stab.glu) + s(hdl) + gender,family = binomial, data = train_data,
                    method = "REML",
                    select = TRUE,
                    gamma = 1.4)
summary(select_model)

# eval
select_predicted_probs <- predict(select_model, test_data, type = "response")
select_predicted_classes <- ifelse(select_predicted_probs > threshold, 1, 0)
select_conf_matrix <- table(select_predicted_classes, test_data$dtest)
print(select_conf_matrix)
cat("accuracy: ", sum(diag(select_conf_matrix)) / sum(select_conf_matrix), "\n")
cat("misclassification rate: ", 1 - sum(diag(select_conf_matrix)) / sum(select_conf_matrix), "\n")
```
